m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library(httr)
library(jsonlite)
source("api-key.R")
library(dplyr)
## I got a free account at coinapi.io
## Free account provides 100 daily requests free.
## The next tier allows 1000 daily requests for US$79/month
base     <- "https://rest.coinapi.io/"
endpoint <- "/v1/twitter/latest?"
api_key  <- paste0("apikey=", api)
## Create
call <- paste0(base, endpoint, api_key)
print(call)
# call
## Retrieve data via GET call
get_tweets <- GET(call)
## Returns class "response"
class(get_tweets)
## Process into a data table
get_tweets_text <- content(get_tweets, "text")  # Convert to "character"
twitter_data <- fromJSON(get_tweets_text, flatten = TRUE) # Flatten into list
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
test <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, test[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
View(twitter_data)
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("dplyr")
source("data.R")
test <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, test[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library("knitr")
View(twitter_data)
twitter_data <- select(twitter_data, created_at, text, user.profile_image_url, user.followers_count)
View(twitter_data)
kable(twitter_data)
formatted <- kable(twitter_data)
class(formatted)
formatted
View(twitter_data)
colnames(twitter_data) <- c("Date_and_Time", "Tweet", "Profile_Picture", "Followers")
View(twitter_data)
twitter_data$Profile_Picture <- paste0("![](", full_table$Photo, ")")
twitter_data$Profile_Picture[twitter_data$Profile_Picture == "![](NA)", "Photo"] <- "Not available"
twitter_data$Profile_Picture <- paste0("![](", twitter_data$Profile_Picture, ")")
twitter_data$Profile_Picture[twitter_data$Profile_Picture == "![](NA)", "Photo"] <- "Not available"
twitter_data$Profile_Picture[twitter_data$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
twitter_data$Profile_Picture <- paste0("![](", twitter_data$Profile_Picture, ")")
twitter_data$Profile_Picture[twitter_data$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
View(test)
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("dplyr")
library("knitr")
source("data.R")
# ALL FOR WORD CLOUD
tweets <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, tweets[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#ALL FOR DISPLAYING TWEETS
display <- select(twitter_data, user.profile_image_url, text, created_at, user.followers_count)
#Change column names
colnames(display) <- c("Date_and_Time", "Tweet", "Profile_Picture", "Followers")
# Change photo and email to correct format to show in index
display$Profile_Picture <- paste0("![](", display$Profile_Picture, ")")
display$Profile_Picture[display$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
formatted <- kable(display)
View(display)
display$Profile_Picture[display$Profile_Picture == "![](NA)", "Profile_Picture"]
display$Profile_Picture == "![](NA)"
"Profile_Picture"
display$Profile_Picture[display$Profile_Picture == "![](NA)",] <- "Not available"
display$Profile_Picture[display$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
display[display$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("dplyr")
library("knitr")
source("data.R")
# ALL FOR WORD CLOUD
tweets <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, tweets[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#ALL FOR DISPLAYING TWEETS
display <- select(twitter_data, user.profile_image_url, text, created_at, user.followers_count)
#Change column names
colnames(display) <- c("Profile_Picture", "Tweet", "Date_and_Time", "Followers")
# Change photo and email to correct format to show in index
display$Profile_Picture <- paste0("![](", display$Profile_Picture, ")")
display[display$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
View(display)
display <- filter(display, Tweet != NA)
is.na()
display <- filter(display, is.na(Tweet) == FALSE)
display <- select(twitter_data, user.profile_image_url, text, created_at, user.followers_count)
#Change column names
colnames(display) <- c("Profile_Picture", "Tweet", "Date_and_Time", "Followers")
# Change photo and email to correct format to show in index
display$Profile_Picture <- paste0("![](", display$Profile_Picture, ")")
display[display$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
display <- filter(display, is.na(Tweet) == FALSE)
View(tweets)
d
shiny::runApp('C:/Users/Dayoung Cheong/Desktop/a8-shiny-dayoungcheong')
runApp('C:/Users/Dayoung Cheong/Desktop/a8-shiny-dayoungcheong')
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("dplyr")
library("knitr")
source("data.R")
# ALL FOR WORD CLOUD
tweets <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, tweets[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
d
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("dplyr")
library("knitr")
source("data.R")
# ALL FOR WORD CLOUD
tweets <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, tweets[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("dplyr")
library("knitr")
source("data.R")
# ALL FOR WORD CLOUD
tweets <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, tweets[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("dplyr")
library("knitr")
source("data.R")
# ALL FOR WORD CLOUD
tweets <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, tweets[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#ALL FOR DISPLAYING TWEETS
display <- select(twitter_data, user.profile_image_url, text, created_at, user.followers_count)
#Change column names
colnames(display) <- c("Profile_Picture", "Tweet", "Date_and_Time", "Followers")
# Change photo and email to correct format to show in index
display$Profile_Picture <- paste0("![](", display$Profile_Picture, ")")
display[display$Profile_Picture == "![](NA)", "Profile_Picture"] <- "Not available"
display <- filter(display, is.na(Tweet) == FALSE)
formatted <- kable(display)
display
View(display)
?gsub
gsub("[:punct:]", "", display$Date_and_Time)
View(gsub("[:punct:]", "", display$Date_and_Time))
View(gsub("\\s*\\w*$"", "", display$Date_and_Time))
View(gsub("\\s*\\w*$", "", display$Date_and_Time))
View(gsub("\\s*\=\w*$", "", display$Date_and_Time))
View(gsub("\\s*\w*$", "", display$Date_and_Time))
View(gsub("\\s*\\w", "", display$Date_and_Time))
View(gsub("\\s*\\\w*$", "", display$Date_and_Time))
View(gsub("\\s*\\w*\\w*$", "", display$Date_and_Time))
removeWords("+0000",display$Date_and_Time)
display
require("tm")
removeWords("+0000",display$Date_and_Time)
?regex
View(gsub("+0000", "", display$Date_and_Time))
View(gsub(" +0000 ", "", display$Date_and_Time))
View(gsub(" +0000", "", display$Date_and_Time))
View(gsub("+0000", "", display$Date_and_Time))
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
library(shiny)
library(shinythemes)
library(dplyr)
library(ggplot2)
install.packages(shinythemes)
install.packages("shinythemes")
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
?wordcloud_rep
??wordcloud_rep
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
library(shiny)
library(shinythemes)
library(dplyr)
library(ggplot2)
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("knitr")
source("data.R")
# Define the server
server <- function(input, output) {
# ALL FOR WORD CLOUD
tweets <- twitter_data %>%
select(text)
text <- ""
for (row in 1:100) {
text <- paste(text, tweets[row,])
}
data <- Corpus(VectorSource(text))
inspect(data)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data <- tm_map(data, toSpace, " ' ")
# Convert the text to lower case
data <- tm_map(data, content_transformer(tolower))
# Remove numbers
data <- tm_map(data, removeNumbers)
# Remove english common stopwords
data <- tm_map(data, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
data <- tm_map(data, removeWords, c("RT", "@"))
# Remove punctuations
data <- tm_map(data, removePunctuation)
# Eliminate extra white spaces
data <- tm_map(data, stripWhitespace)
dtm <- TermDocumentMatrix(data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
#d <- filter(d, freq >= 3)
set.seed(1234)
wordcloud <- renderPlot ({ wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2")) })
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
# Setup
library(shiny)
library(shinythemes)
library(dplyr)
library(ggplot2)
library(wordcloud)
source("functions.R")
server <- function(input, output) {
output$wordcloud <- renderplot ({
wordcloud(words = d$word, freq = d$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2")) })
}
runApp('C:/Users/Dayoung Cheong/Desktop/INFO-201-Final-Project-AD5')
